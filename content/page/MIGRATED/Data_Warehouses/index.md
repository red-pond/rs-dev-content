---
title: Riverscapes Warehouse
banner: true
origin: riverscapes-website-jekyll/Data_Warehouses/signup.md
---

The Riverscapes Consortium organizes and serves data via a  *[data warehouse](http://data.riverscapes.net)* <Image noWrap src="/images/data/RiverscapesWarehouseCloud_24.png" />. The data warehouse provides access to both the underlying data (packaged in [riverscapes projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/)) as well as making these data explorable via a  [warehouse explorer](/Data_Warehouses/#warehouse-explorer-concept) or [interactive web maps](/Data_Warehouses/#web-maps). We only serve and host data packaged in fully  [Riverscapes-Compliant](/Tools) <Image  noWrap src="/images/rc/RiverscapesCompliant_24.png" />  [Riverscapes Projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) <Image  noWrap src="/images/data/RiverscapesProject_24.png" />.

## GOAL

<Image src="/images/data/RiverscapesWarehouseCloud_128.png" />
Make it easier to catalog, share, discover and retrieve the products of riverscapes analysis and modelling.

<Button imageSrc="/images/data/RiverscapesWarehouseCloud_32png.png" to="http://data.riverscapes.net" title="Get Data Now from Riverscapes Warehouse"/>
    

## Advantages

<Image src="/images/data/Riverscapes Warehouse Loggin.png" to="http://data.riverscapes.net" /> The advantages of [riverscapes projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) being hosted in a data warehouse can include:

- Searchable and queryable [Warehouse Explorer](/Data_Warehouses#warehouse-explorer-concept) Catalog
- Custom [Web-Maps](/Data_Warehouses#web-maps)
- Custom field and desktop [Apps](/Data_Warehouses#apps---pwas) <Image src="/images/tools/PWA.png" />
- Secure cloud hosting  (typically in <Image  src="/images/data/aws_24.png" to="https://aws.amazon.com"/> [S3](https://aws.amazon.com/s3/faqs/)) with:
  - Easy public sharing
  - Full user access permission control
- Full <Image  src="/images/data/aws_24.png" to="https://aws.amazon.com" />  integration with [EC2](https://aws.amazon.com/ec2/?nc2=type_a) and [Lambda](https://aws.amazon.com/lambda/?nc2=type_a) for cloud-computing of [Production-Grade](https://riverscapes.github.io/riverscapes-website/Tools/#tool-status) Riverscapes Models.
-  [Creative Commons licensing](https://creativecommons.org/licenses/) of datasets
- Ability to mint [DOIs](https://www.doi.org/faq.html) <Image src="/images/data/DOI_24.png" to="https://www.doi.org/faq.html"/> to make datasets citable
- [OGC API](http://www.ogcapi.org/) access to riverscapes projects and warehouse for programmers <Image  src="/images/data/api_24.png" />
-  [OGC Web Map Tile Services](https://www.opengeospatial.org/standards/wmts) access to your datasets
- Searchable and discoverable in [RAVE](http://rave.riverscapes.net) GIS Toolbars




## Overview
In this 8 minute video, we show off what these warehouses buy you in terms of housekeeping and reaching broader audiences.

<Youtube embedId="iuYYsJiTQRI" />

-----
## Riverscape Warehouse Concepts

###  Warehouse Explorer Concept

<Image src="/images/data/RC_WarehouseExplorer.png" to="https://northarrowresearchlabs.github.io/riverscapes/#/" />

Part of the advantage of serving and hosting data in the [Riverscapes Warehouse](http://data.riverscapes.net)  <Image src="/images/data/RiverscapesWarehouseCloud_24.png" /> is the ability to catalog and index the data so it easily searchable,  queried and discoverable.

<Image src="/images/data/WarehouseCHAMP.png" noWrap />
Example view of a fully searchable and querable data warehouse.

### CHaMP Example

When the [Columbia Habitat Monitoring Program](http://champmonitoring.org) (CHaMP) was operational, the program produced an immense amount of raw monitoring data, derivative products, model analysis products, and various outputs. For example, from 2011 to 2017, over 958 sites were monitored for fish habitat producing (ISEMP/CHAMP, 2018)., CHaMP crews conducted over 5000 visits to over 950 sites producing a mountain of monitoring data. All of the visit and topographic data was made available in [champmonitoring.org](http://champmonitoring.org). However, the program produced a much richer range of reach scale, network scale and population scale analysis and synthesis products, which cm.org was not designed to accommodate. To test the utility of the Riverscapes Warehouse context, we created a warehouse explorer for the [CHaMP Riverscapes Warehouse](https://data.riverscapes.net/#/CHaMP). Some of its utility is illustrated in the video below.

<Youtube embedId="llGthTDUjfo" caption="Video explaining data warehouse concepts and illustrating some of its utility." />

- ISEMP/CHAMP. (2018) [Integrated Status and Effectiveness Monitoring Program (BPA Project 2003-017-00) and Columbia Habitat Monitoring Program (BPA Project 2011-006-00) . Final Technical Report for Bonneville Power Administration](https://www.researchgate.net/publication/329514287_Integrated_Status_and_Effectiveness_Monitoring_Program_BPA_Project_2003-017-00_and_Columbia_Habitat_Monitoring_Program_BPA_Project_2011-006-00_Final_Technical_Report_for_Bonneville_Power_Administration). 1280 pages.



### Fully-Customizable

Any group or organization can develop their own custom [Program](https://riverscapes.net/Data_Warehouses/gettingaround.html#programs-and-access) in the [Riverscapes Data Warehouse](http://data.riverscapes.net), and control how and where it is hosted, who can access it, who has what permissions, etc.

-----


## Web-Maps

<Image  src="/images/data/BRAT_Risk.png" />

One of the real values in hosting your [Riverscapes Projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) <Image noWrap src="/images/data/RiverscapesProject_24.png" /> in a Riverscapes Warehouse  <Image noWrap src="/images/data/RiverscapesWarehouseCloud_24.png" />, is that web-maps can be produced that allow non-GIS users and non-modelers to interact with  riverscape project outputs and explore them. This is an excellent platform to make the outputs of [Riverscapes Tools](/Tools) accessible to managers and practitioners to inform riverscape management.

**2021 January Update** : BLM Montana/Dakotas is currently funding the development of this **Web-RAVE** functionality by extending the [Riverscapes Analysis Visualization Explorer - RAVE](http://rave.riverscapes.net). Any project in the warehouse will be visible in an interactive webmap.

### Example of BRAT
<Image src="/images/tools/brat-logo-wgraytxt_3.png" to="https://brat.riverscapes.net" />
The [Beaver Restoration Assessment Tool](https://tools.riverscapes.net/brat) is one of the RC's more mature network model tools. Thanks to BRAT being refactored to produce [Riverscapes Projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) <Image noWrap  src="/images/data/RiverscapesProject_24.png" />, and being hosted in a Riverscapes Warehouse  <Image noWrap src="/images/data/RiverscapesWarehouseCloud_24.png" />, we can produce interactive web maps.

While many platforms exist to publish GIS data and share it (e.g [ArcGIS Online](https://www.esri.com/en-us/arcgis/products/arcgis-online/overview)), they lack the ablity to do so while maintaing the integrity and context of a [Riverscapes Project](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/). For example, in one of the old BRAT projects for the state of Utah the data can be downloaded from [Utah AGRC](http://gis.utah.gov/data/bioscience-overview/), [Databasin interactive webmap](http://databasin.org/datasets/1420ffb7e9674753a5fb626e2b830c1f), or directly from [ETAL Box File Server](https://usu.box.com/v/UtahBRATData). Only the  [Databasin interactive webmap](http://databasin.org/datasets/1420ffb7e9674753a5fb626e2b830c1f) download provided a web map, and without any of the context of the rich projects. When users download all the files off our  [ETAL Box File Server](https://usu.box.com/v/UtahBRATData), the need to know a lot about how the model works and how the outputs were produced to find the right context data.

-----

## Apps - PWAs

<Image  src="/images/data/PWA_LTPBR_Design3.png" />

The future of App develpoment to work across platforms (i.e. iOS, Android, Windows, Linux, etc.) is in progressive web-apps (PWAs) <Image noWrap src="/images/tools/PWA.png" />. Another advantage of hosting  your [Riverscapes Projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) <Image noWrap  src="/images/data/RiverscapesProject_24.png" /> in a Riverscapes Warehouse  <Image noWrap src="/images/data/RiverscapesWarehouseCloud_24.png" />, is that PWA(s) can be developed and deployed to make field or desktop interactive apps to allow users to collect data, do analysis and have it direclty interact with and even update a Riverscapes Project.




### Example of Low-Tech Process-Based Restoration PWA

<Image src="/images/data/PWA_LTPBR_Design2.png" />
The practice of [Low-Tech Process-Based Restoration of Riverscapes](https://lowtechpbr.restoration.usu.edu) is something that many members of the Riverscapes Consortium have been working on over the past decade. While a recent [manual](https://lowtechpbr.restoration.usu.edu/manual) helped define a standard of practice for design, tracking that information centrally in a design app (a PWA), and having those designs and subsequent monitoring be stored in [Riverscapes Projects](/Tools/Technical_Reference/Documentation_Standards/Riverscapes_Projects/) would allow:
- The designs conducted in the field, to become immediately useful for GIS analyses back at the desktop.
- Allow holding and submitting designs to central [riverscapes warehouses](/Data_Warehouses)
- Facilitate easier and more transparent action-effectiveness monitoring in the context of those designs.

In the video below Philip Bailey of [North Arrow Research](https://northarrowresearch.com) illustrates how such a PWA can work (don't get too excited, its a western town movie set, it is not actually fully plumbed yet ~ i.e. its a [proof of concept](/Tools/discrimination.html#tool-grade) level of development):

<Youtube embedId="t95xxkhYOcA" />

-----

## Dataset Discrimination

We refer to ‘datasets’ as any input(s), output(s) or intermediate(s) used or produced by our various analyses, [tools](/Tools/) and workflows within the Riverscapes Consortium.  Within the warehouse, we assign to each "dataset" node or instance within a Riverscapes Project we use a couple of concepts to differentiate and contextualize that data :
- **Dataset Grade** - Describes the rank of dataset curation using an adaptation of  [Bloom's Taxonomy of Educational Objectives](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/)
- **Data Product Status Tags** - Tracks overall status, degree of quality assurance and control, and data generation methods.  

As scientists and analysts, we produce a plethora of datasets, some of which go no further than an exploratory analysis and some which are carefully documented, vetted, and validated before being made for external consumption. Not all datasets will proceed sequentially through all stages of dataset status below and some stages are reiterated (e.g. after expert calibration, an output may be requeued for QA/QC assurance. The idea behind dataset discrimination is to keep track of how far, and for what purpose a dataset was

In this 8 minute video, we lay out some concepts we're exploring with respect to dataset status:

<Youtube embedId="msBhCp6vCsc" />


### Dataset Rank
Not all datasets are created equal, nor have all received the same amount of attention, curation, validating, curation and or story telling. Drawing from and adapting [Bloom's Taxonomy of Educational Objectives](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/), we define dataset grade in terms of a similar hierarchy of dataset curation (instead of skills and abilities) with six levels:
1. **Knowledge-Rank** -  A dataset representing raw data and observations.
2. **Comprehension-Rank** - A dataset that is a derivative product from raw data or observation (e.g. a surface interpolated from raw sample points)
3. **Application-Rank** - A dataset that represents the typical outputs generated in one realization from a tool or model.
4. **Analysis-Rank** - A dataset that represents an an analysis, summary or interpretation from an application-rank dataset.
5. **Synthesis-Rank** - A dataset that involves the pulling together of multiple analysis-rank datasets to describe a larger problem.
6. **Evaluation-Rank** - A broader summary dataset that provides direct answers or insights into key scientific knowledge gaps or key management questions (e.g. what is published in a peer-reviewed paper as an "original contribution" or used as a basis for decision making)

In general, the higher tiered datasets represent what is filtered out through scientific inquiry from more basic and prolific datasets and observations into a higher form of knowledge. Higher-tiered datasets have more utility to managers to inform decision making, but scientists often at least want the transparency of knowing what datasets went into informing that  synthesis or evaluation. Riverscapes Projects impose this transparency of what evidence every dataset originated from and allow iterative inquiry and exploration.



#### Idea from CHaMP
The idea to use [Bloom's Taxonomy of Educational Objectives](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/) to communicate the rank or type of curation a dataset had received grew out of a need to communicate what utility the many different datasets we were producing in the [CHaMP](http://champmonitoring.org) had. The figure below shows how we referred to datasets as "products" and uses specific examples of RC-tools and models to illustrate the ideas:
<Image src="https://lh5.googleusercontent.com/MrlolkkwfO0OC1pZNKDKkCcoebKTYbGKbVpO5H2vpd7ItVFi-6lVvmUNY9o4TMK1UxQizAGkZwaoBuLntsZvO8mfE4gsh9ohNmfxxhZBG0owahyAr_Tv_eUdt31REXy-MPKEeSMR" to="https://lh5.googleusercontent.com/MrlolkkwfO0OC1pZNKDKkCcoebKTYbGKbVpO5H2vpd7ItVFi-6lVvmUNY9o4TMK1UxQizAGkZwaoBuLntsZvO8mfE4gsh9ohNmfxxhZBG0owahyAr_Tv_eUdt31REXy-MPKEeSMR" />

### Dataset  Status Tags

We use three optional status tags:
1. Overall Status,
2. QA/QC Review, and
3. Data Generation

to track the development of a dataset. However, it is the Overall Status of a dataset that is most important for tracking its progression within a Riverscape Warehouse.

| Status Tags | Overall Status | QA/QC Review | Data Generation |
|-------------|----------------|-------------------|-----------------|
|  |  | None | None |
|  | Exploratory | Automated Testing | End-User |
|  | Provisional | Manual Testing | Manual |
|  | Final | Expert Calibrated | Automated-Local |
|  | Promoted | Validated | Automated-Cloud |


#### Overall Status
Where in the dataset life cycle the dataset  exists. The four status choices represent a progression.
  - **Exploratory** - Preliminary datasets produced by an analyst to explore how well a particular analysis works, or to what extent a dataset gives insights into specific questions (e.g., an individual model run used for a talk).  This is as far as the vast majority of analyses get.
  - **Provisional** - A dataset that has undergone some degree of automated or manual QA/QC testing.
  - **Final** - A dataset that has been validated and is trusted for inclusion in the riverscape warehouse. Upon elevation to a finalized status a dataset is available for use by  team members and authorized partners. At this point the dataset has a DOI assigned so a static version is available for later reference.
  - **Promoted** - A dataset promoted from a finalized riverscape warehouse output to ready for external consumption. The degree of documentation and vetting is generally higher than finalized outputs. Examples may include any datasets used in the preparation of a basin or restoration plan or peer-reviewed paper.

#### QA/QC Review

The degree of quality assurance and quality control checks that a dataset has been subjected to. The choices are not a progression per se, and a dataset may undergo just one or all four of these states.
  - **Automated Testing** - All tool-generated outputs undergo some degree of quality assurance and quality control checking to flag outliers and mistakes. When a dataset has received QA/QC evaluation in an automated, centralized, production mode (e.g., GCD results checked for outliers) it is automatically queued for manual editing, checking and fixing.
  - **Manual Testing** - A manual, expert evaluation of a dataset and its reporting.
  - **Expert Calibrated** - An optional step of modifying model outputs by model iteration or analysis to produce new output based on expert modification of inputs and/or parameters to more realistic values.
  - **Validated**- A dataset can be considered validated after it has undergone some form of testing and the relative quality of that dataset has been assessed and reported. If the inputs and/or parameters have been calibrated or modified with expert insights and the dataset generation has been iterative, the reporting includes how dataset quality has changed with that calibration process.

#### Data Generation

How the data datasets were generated
  - **Automated Local**- Generated via batch processing using local tools and/or [workbench](http://workbench.northarrowresearch.com/).
  -  **Automated Cloud -** Generated via cloud processing engines (e.g., <Image noWrap src="/images/data/aws_24.png" to="https://aws.amazon.com"/> EC2 or Lambda)
  -  **Manual** - Generated via local tools on an individual basis.
